# Florida Housing Price Predictor - Model Explanation
# This file contains detailed explanations of the code structure and algorithms

"""
RIDGE REGRESSION HOUSING PRICE PREDICTOR
========================================

This application uses Ridge Regression to predict Florida housing prices based on historical data.
Below is a detailed breakdown of how each component works:

1. DATA LOADING AND PREPROCESSING
================================

def load_data():
    # Loads CSV file containing Florida State Housing Price Index (STHPI) data
    # Converts dates to datetime format for time series analysis
    # Removes any missing values to ensure clean data
    
The dataset spans from 1975 to 2025 with quarterly observations.
Each row contains:
- observation_date: Quarter date (YYYY-MM-DD)
- FLSTHPI: Housing price index value (100 = baseline year 1980)

2. FEATURE ENGINEERING
=====================

def engineer_features(df):
    # Creates multiple types of features from the raw time series data
    
    TEMPORAL FEATURES:
    - year: Extract year from date
    - quarter: Extract quarter (1,2,3,4)
    - month: Extract month number
    
    CYCLICAL FEATURES (for seasonality):
    - quarter_sin: sin(2π × quarter/4) - captures quarterly cycles
    - quarter_cos: cos(2π × quarter/4) - captures quarterly cycles
    
    Why sine/cosine? These mathematical functions naturally represent cyclical patterns.
    They ensure that Q4 (winter) and Q1 (next winter) are treated as similar.
    
    TREND FEATURES:
    - days_since_start: Linear time progression
    - years_since_start: Normalized time progression
    
    PRICE HISTORY FEATURES:
    - price_lag_1: Previous quarter's price (momentum)
    - price_lag_4: Same quarter last year (year-over-year comparison)
    - price_ma_4: 4-quarter moving average (short-term trend)
    - price_ma_8: 8-quarter moving average (long-term trend)
    - price_change: Quarter-over-quarter percentage change
    - price_change_4: Year-over-year percentage change

3. RIDGE REGRESSION MODEL
========================

def train_ridge_model(df_features, test_size=0.2, random_state=42):
    
    WHAT IS RIDGE REGRESSION?
    Ridge regression is linear regression with L2 regularization:
    
    Standard Linear Regression:
    minimize: Σ(actual - predicted)²
    
    Ridge Regression:
    minimize: Σ(actual - predicted)² + α × Σ(coefficient²)
    
    The α (alpha) parameter controls regularization strength:
    - α = 0: Same as standard linear regression
    - α > 0: Adds penalty for large coefficients
    - Higher α: More regularization, simpler model
    
    WHY RIDGE FOR HOUSING PRICES?
    1. Multicollinearity: Many time features are correlated
    2. Overfitting prevention: Keeps model generalizable
    3. Stability: Produces consistent predictions
    4. Interpretability: Still a linear model
    
    TRAINING PROCESS:
    
    Step 1: Feature Selection
    - Exclude target variable (FLSTHPI) and date column
    - Use all engineered features as predictors
    
    Step 2: Temporal Data Split
    - Training: First 80% of time series (older data)
    - Testing: Last 20% of time series (recent data)
    - Important: No random shuffling - maintains time order
    
    Step 3: Feature Scaling
    - StandardScaler: (feature - mean) / standard_deviation
    - Ensures all features have similar scales
    - Prevents features with larger values from dominating
    
    Step 4: Hyperparameter Tuning
    - Tests different alpha values: [0.1, 1.0, 10.0, 100.0, 1000.0]
    - Uses 5-fold cross-validation on training data
    - Selects alpha with highest R² score
    
    Step 5: Final Model Training
    - Trains Ridge regression with best alpha
    - Learns optimal coefficients for each feature
    - Each coefficient represents feature importance
    
    Step 6: Performance Evaluation
    - R² Score: Proportion of variance explained (0-1, higher better)
    - MAE: Mean Absolute Error (average prediction error)
    - RMSE: Root Mean Square Error (penalizes large errors)

4. FUTURE PREDICTIONS
====================

def generate_future_predictions(df_features, model_results, periods=20):
    
    PREDICTION PROCESS:
    
    Step 1: Create Future Dates
    - Generate quarterly dates starting from last observed date
    - Number of periods is user-configurable
    
    Step 2: Engineer Future Features
    - Temporal features: Calculate from future dates
    - Cyclical features: Apply same sine/cosine transformations
    - Trend features: Extrapolate time progression
    
    Step 3: Handle Lagged Features
    - Use last known prices for lag features
    - Make assumptions about price changes
    - Simplified approach for demonstration
    
    Step 4: Apply Trained Model
    - Scale features using same scaler from training
    - Use trained Ridge model to predict prices
    - Output predicted housing price index values

5. VISUALIZATION AND ANALYSIS
=============================

The Streamlit app provides:
- Historical price trends (line charts)
- Model performance metrics
- Feature correlation analysis
- Future predictions with confidence
- Interactive parameter adjustment

PERFORMANCE INTERPRETATION:
- R² > 0.8: Excellent model performance
- R² 0.6-0.8: Good model performance  
- R² < 0.6: May need more features or different approach

The model achieves good performance by combining:
1. Multiple time-based features
2. Regularization to prevent overfitting
3. Proper temporal validation
4. Feature scaling for stability

This approach is industry-standard for time series regression problems
and provides interpretable, reliable housing price predictions.
"""

# Example usage and code snippets for learning:

def example_ridge_regression():
    """
    Simple example showing Ridge regression basics
    """
    from sklearn.linear_model import Ridge
    from sklearn.preprocessing import StandardScaler
    import numpy as np
    
    # Sample data
    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])  # Features
    y = np.array([3, 5, 7, 9])  # Target values
    
    # Scale features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Train Ridge model
    ridge = Ridge(alpha=1.0)  # alpha controls regularization
    ridge.fit(X_scaled, y)
    
    # Make predictions
    predictions = ridge.predict(X_scaled)
    
    # Model coefficients show feature importance
    print("Coefficients:", ridge.coef_)
    print("Intercept:", ridge.intercept_)

def example_feature_engineering():
    """
    Example of creating cyclical features for seasonality
    """
    import pandas as pd
    import numpy as np
    
    # Sample quarterly data
    dates = pd.date_range('2020-01-01', periods=8, freq='Q')
    df = pd.DataFrame({'date': dates, 'quarter': dates.quarter})
    
    # Create cyclical features
    df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)
    df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)
    
    print(df)
    # This shows how Q1 and Q1 (next year) have similar sin/cos values
